{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0], "episode_lengths": [500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22275726516525468, "mean_inference_ms": 1.759738474339991, "mean_action_processing_ms": 0.11801124214530587, "mean_env_wait_ms": 0.830509088613413, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1000, "timesteps_this_iter": 0, "agent_timesteps_total": 2000, "timers": {"sample_time_ms": 2982.983, "sample_throughput": 335.235, "load_time_ms": 0.999, "load_throughput": 1000788.356, "learn_time_ms": 98.001, "learn_throughput": 10204.002, "update_time_ms": 1.999}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 0.0005, "total_loss": 0.022643541917204857, "policy_loss": -0.0013853585794567636, "vf_loss": 0.040038274601101875, "vf_explained_var": -0.003197312355041504, "kl": 0.0004019092494923493, "entropy": 1.6089769005775452, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1000, "num_agent_steps_sampled": 2000, "num_steps_trained": 1000, "num_agent_steps_trained": 2000}, "done": false, "episodes_total": 2, "training_iteration": 1, "trial_id": "dd276_00000", "experiment_id": "90f9f4b6b038459abfa62bd7b59bc899", "date": "2023-04-29_14-39-24", "timestamp": 1682771964, "time_this_iter_s": 3.0501034259796143, "time_total_s": 3.0501034259796143, "pid": 8248, "hostname": "DESKTOP-2RBON3P", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 2, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 2, "reward_type": "RewardType.INDIVIDUAL", "map_name": "testing_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 10, "framework": "torch", "num_workers": 1, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "complete_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_testing_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 10, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000212CEF04700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3.0501034259796143, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 58.3, "ram_util_percent": 60.32000000000001}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.75, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22372108577619657, "mean_inference_ms": 1.6919339985133839, "mean_action_processing_ms": 0.11030547115905383, "mean_env_wait_ms": 0.7800204340669045, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2000, "timesteps_this_iter": 0, "agent_timesteps_total": 4000, "timers": {"sample_time_ms": 2800.841, "sample_throughput": 357.036, "load_time_ms": 0.5, "load_throughput": 2001576.712, "learn_time_ms": 94.002, "learn_throughput": 10638.111, "update_time_ms": 2.023}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1, "cur_lr": 0.0005, "total_loss": 0.005099005764350295, "policy_loss": -0.0007837593881412364, "vf_loss": 0.02191021665930748, "vf_explained_var": 0.047409892082214355, "kl": 0.00028295311602266615, "entropy": 1.605574905872345, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2000, "num_agent_steps_sampled": 4000, "num_steps_trained": 2000, "num_agent_steps_trained": 4000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 4, "training_iteration": 2, "trial_id": "dd276_00000", "experiment_id": "90f9f4b6b038459abfa62bd7b59bc899", "date": "2023-04-29_14-39-27", "timestamp": 1682771967, "time_this_iter_s": 2.5336833000183105, "time_total_s": 5.583786725997925, "pid": 8248, "hostname": "DESKTOP-2RBON3P", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 2, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 2, "reward_type": "RewardType.INDIVIDUAL", "map_name": "testing_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 10, "framework": "torch", "num_workers": 1, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "complete_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_testing_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 10, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000212CF0E2F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5.583786725997925, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 55.075, "ram_util_percent": 60.325}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.6666666666666666, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.3333333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 0.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21483844876097577, "mean_inference_ms": 1.5948834662695237, "mean_action_processing_ms": 0.10224614748709637, "mean_env_wait_ms": 0.7307796189559296, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3000, "timesteps_this_iter": 0, "agent_timesteps_total": 6000, "timers": {"sample_time_ms": 2442.323, "sample_throughput": 409.446, "load_time_ms": 0.333, "load_throughput": 3002365.068, "learn_time_ms": 91.296, "learn_throughput": 10953.33, "update_time_ms": 2.016}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05, "cur_lr": 0.0005, "total_loss": 0.0067415928933769464, "policy_loss": -0.0002856934661981114, "vf_loss": 0.022982675582170486, "vf_explained_var": 0.05523490905761719, "kl": 0.0002986720913197016, "entropy": 1.5970324277877808, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3000, "num_agent_steps_sampled": 6000, "num_steps_trained": 3000, "num_agent_steps_trained": 6000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 6, "training_iteration": 3, "trial_id": "dd276_00000", "experiment_id": "90f9f4b6b038459abfa62bd7b59bc899", "date": "2023-04-29_14-39-28", "timestamp": 1682771968, "time_this_iter_s": 1.6834557056427002, "time_total_s": 7.267242431640625, "pid": 8248, "hostname": "DESKTOP-2RBON3P", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 2, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 2, "reward_type": "RewardType.INDIVIDUAL", "map_name": "testing_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 10, "framework": "torch", "num_workers": 1, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "complete_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_testing_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 10, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000212CEF04700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7.267242431640625, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 17.0, "ram_util_percent": 60.4}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.625, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.3125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20726436606287812, "mean_inference_ms": 1.5205191884152245, "mean_action_processing_ms": 0.09582428625530356, "mean_env_wait_ms": 0.6956654273474567, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4000, "timesteps_this_iter": 0, "agent_timesteps_total": 8000, "timers": {"sample_time_ms": 2277.081, "sample_throughput": 439.159, "load_time_ms": 0.508, "load_throughput": 1966617.747, "learn_time_ms": 89.712, "learn_throughput": 11146.726, "update_time_ms": 2.262}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.025, "cur_lr": 0.0005, "total_loss": 0.0068155506160110235, "policy_loss": -0.0004896126962266878, "vf_loss": 0.02317162323743105, "vf_explained_var": -0.013645052909851074, "kl": 0.00027644074829347165, "entropy": 1.5873371958732605, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4000, "num_agent_steps_sampled": 8000, "num_steps_trained": 4000, "num_agent_steps_trained": 8000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 8, "training_iteration": 4, "trial_id": "dd276_00000", "experiment_id": "90f9f4b6b038459abfa62bd7b59bc899", "date": "2023-04-29_14-39-30", "timestamp": 1682771970, "time_this_iter_s": 1.7433230876922607, "time_total_s": 9.010565519332886, "pid": 8248, "hostname": "DESKTOP-2RBON3P", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 2, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 2, "reward_type": "RewardType.INDIVIDUAL", "map_name": "testing_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 10, "framework": "torch", "num_workers": 1, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "complete_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_testing_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 10, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000021359B524C0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9.010565519332886, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 18.1, "ram_util_percent": 60.349999999999994}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.5, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20135625615106031, "mean_inference_ms": 1.4632515883430561, "mean_action_processing_ms": 0.09170638261095802, "mean_env_wait_ms": 0.6690128307807951, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5000, "timesteps_this_iter": 0, "agent_timesteps_total": 10000, "timers": {"sample_time_ms": 2181.484, "sample_throughput": 458.404, "load_time_ms": 0.407, "load_throughput": 2458272.184, "learn_time_ms": 88.76, "learn_throughput": 11266.276, "update_time_ms": 2.21}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0125, "cur_lr": 0.0005, "total_loss": -0.015244358219206333, "policy_loss": -0.00046554690622713224, "vf_loss": 0.000898810540093109, "vf_explained_var": -1.0, "kl": 0.0003431683085148851, "entropy": 1.5681911706924438, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5000, "num_agent_steps_sampled": 10000, "num_steps_trained": 5000, "num_agent_steps_trained": 10000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 10, "training_iteration": 5, "trial_id": "dd276_00000", "experiment_id": "90f9f4b6b038459abfa62bd7b59bc899", "date": "2023-04-29_14-39-32", "timestamp": 1682771972, "time_this_iter_s": 1.7491891384124756, "time_total_s": 10.759754657745361, "pid": 8248, "hostname": "DESKTOP-2RBON3P", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 2, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 2, "reward_type": "RewardType.INDIVIDUAL", "map_name": "testing_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 10, "framework": "torch", "num_workers": 1, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "complete_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_testing_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 10, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000021359B52670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.759754657745361, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 24.73333333333333, "ram_util_percent": 60.36666666666667}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.5, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19669452829397185, "mean_inference_ms": 1.4196746947119936, "mean_action_processing_ms": 0.088119195914148, "mean_env_wait_ms": 0.6485872649408658, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6000, "timesteps_this_iter": 0, "agent_timesteps_total": 12000, "timers": {"sample_time_ms": 2124.027, "sample_throughput": 470.804, "load_time_ms": 0.339, "load_throughput": 2949926.621, "learn_time_ms": 89.442, "learn_throughput": 11180.408, "update_time_ms": 2.176}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00625, "cur_lr": 0.0005, "total_loss": 0.007465788628906012, "policy_loss": 0.00012937524425815639, "vf_loss": 0.022686583921313286, "vf_explained_var": 0.026040196418762207, "kl": 0.0001408650032415082, "entropy": 1.5351056456565857, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 6000, "num_agent_steps_sampled": 12000, "num_steps_trained": 6000, "num_agent_steps_trained": 12000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 12, "training_iteration": 6, "trial_id": "dd276_00000", "experiment_id": "90f9f4b6b038459abfa62bd7b59bc899", "date": "2023-04-29_14-39-34", "timestamp": 1682771974, "time_this_iter_s": 1.8078758716583252, "time_total_s": 12.567630529403687, "pid": 8248, "hostname": "DESKTOP-2RBON3P", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 2, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 2, "reward_type": "RewardType.INDIVIDUAL", "map_name": "testing_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 10, "framework": "torch", "num_workers": 1, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "complete_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_testing_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 10, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000021359B524C0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12.567630529403687, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 21.433333333333334, "ram_util_percent": 60.333333333333336}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.5, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.192786279579569, "mean_inference_ms": 1.385513519558881, "mean_action_processing_ms": 0.08549816064938594, "mean_env_wait_ms": 0.6329350952447603, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7000, "timesteps_this_iter": 0, "agent_timesteps_total": 14000, "timers": {"sample_time_ms": 2094.108, "sample_throughput": 477.53, "load_time_ms": 0.291, "load_throughput": 3441581.057, "learn_time_ms": 88.513, "learn_throughput": 11297.715, "update_time_ms": 2.293}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003125, "cur_lr": 0.0005, "total_loss": 0.009112861938774586, "policy_loss": -0.0008393198768608112, "vf_loss": 0.025219200178980827, "vf_explained_var": -0.017978668212890625, "kl": 0.0001405115085135744, "entropy": 1.526745855808258, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 7000, "num_agent_steps_sampled": 14000, "num_steps_trained": 7000, "num_agent_steps_trained": 14000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 14, "training_iteration": 7, "trial_id": "dd276_00000", "experiment_id": "90f9f4b6b038459abfa62bd7b59bc899", "date": "2023-04-29_14-39-36", "timestamp": 1682771976, "time_this_iter_s": 1.8627452850341797, "time_total_s": 14.430375814437866, "pid": 8248, "hostname": "DESKTOP-2RBON3P", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 2, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 2, "reward_type": "RewardType.INDIVIDUAL", "map_name": "testing_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 10, "framework": "torch", "num_workers": 1, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "complete_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_testing_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 10, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000212CF0E2A60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14.430375814437866, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 22.55, "ram_util_percent": 60.25}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.5, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18955410499244282, "mean_inference_ms": 1.3583942947727472, "mean_action_processing_ms": 0.08328720221527482, "mean_env_wait_ms": 0.6211133906431805, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8000, "timesteps_this_iter": 0, "agent_timesteps_total": 16000, "timers": {"sample_time_ms": 2079.745, "sample_throughput": 480.828, "load_time_ms": 0.379, "load_throughput": 2638756.842, "learn_time_ms": 89.357, "learn_throughput": 11191.104, "update_time_ms": 2.507}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0015625, "cur_lr": 0.0005, "total_loss": 0.007763328962028027, "policy_loss": -0.0001879180138930625, "vf_loss": 0.02319585718214512, "vf_explained_var": -0.013215899467468262, "kl": 0.0001392970046002473, "entropy": 1.5244827270507812, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8000, "num_agent_steps_sampled": 16000, "num_steps_trained": 8000, "num_agent_steps_trained": 16000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 16, "training_iteration": 8, "trial_id": "dd276_00000", "experiment_id": "90f9f4b6b038459abfa62bd7b59bc899", "date": "2023-04-29_14-39-38", "timestamp": 1682771978, "time_this_iter_s": 1.9397163391113281, "time_total_s": 16.370092153549194, "pid": 8248, "hostname": "DESKTOP-2RBON3P", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 2, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 2, "reward_type": "RewardType.INDIVIDUAL", "map_name": "testing_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 10, "framework": "torch", "num_workers": 1, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "complete_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_testing_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 10, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000021359B524C0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.370092153549194, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 25.53333333333333, "ram_util_percent": 60.29999999999999}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.5, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18691995210120513, "mean_inference_ms": 1.3366035679005772, "mean_action_processing_ms": 0.0815291342965483, "mean_env_wait_ms": 0.6120405215587008, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9000, "timesteps_this_iter": 0, "agent_timesteps_total": 18000, "timers": {"sample_time_ms": 2074.78, "sample_throughput": 481.979, "load_time_ms": 0.337, "load_throughput": 2968601.447, "learn_time_ms": 89.975, "learn_throughput": 11114.151, "update_time_ms": 2.571}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00078125, "cur_lr": 0.0005, "total_loss": 0.006785825826227665, "policy_loss": 6.935131660434912e-05, "vf_loss": 0.02163204364478588, "vf_explained_var": -0.07333016395568848, "kl": 6.107439154279248e-05, "entropy": 1.4915618300437927, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 9000, "num_agent_steps_sampled": 18000, "num_steps_trained": 9000, "num_agent_steps_trained": 18000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 18, "training_iteration": 9, "trial_id": "dd276_00000", "experiment_id": "90f9f4b6b038459abfa62bd7b59bc899", "date": "2023-04-29_14-39-40", "timestamp": 1682771980, "time_this_iter_s": 1.9911723136901855, "time_total_s": 18.36126446723938, "pid": 8248, "hostname": "DESKTOP-2RBON3P", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 2, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 2, "reward_type": "RewardType.INDIVIDUAL", "map_name": "testing_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 10, "framework": "torch", "num_workers": 1, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "complete_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_testing_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 10, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000021359B52550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18.36126446723938, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 23.53333333333333, "ram_util_percent": 60.36666666666667}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.45, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18505082284896515, "mean_inference_ms": 1.31984938576939, "mean_action_processing_ms": 0.08015484893899226, "mean_env_wait_ms": 0.6046649932009942, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10000, "timesteps_this_iter": 0, "agent_timesteps_total": 20000, "timers": {"sample_time_ms": 2084.288, "sample_throughput": 479.78, "load_time_ms": 0.404, "load_throughput": 2477877.946, "learn_time_ms": 90.271, "learn_throughput": 11077.758, "update_time_ms": 2.714}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.000390625, "cur_lr": 0.0005, "total_loss": -0.011865661479532719, "policy_loss": -0.0001774305700124046, "vf_loss": 0.0032601909479126334, "vf_explained_var": -1.0, "kl": 7.422502518114604e-05, "entropy": 1.4948447942733765, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 10000, "num_agent_steps_sampled": 20000, "num_steps_trained": 10000, "num_agent_steps_trained": 20000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.6, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15678178832617268, "mean_inference_ms": 1.1604281812399726, "mean_action_processing_ms": 0.06657489608035425, "mean_env_wait_ms": 0.5310944284684325, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": true, "episodes_total": 20, "training_iteration": 10, "trial_id": "dd276_00000", "experiment_id": "90f9f4b6b038459abfa62bd7b59bc899", "date": "2023-04-29_14-39-51", "timestamp": 1682771991, "time_this_iter_s": 11.743582725524902, "time_total_s": 30.104847192764282, "pid": 8248, "hostname": "DESKTOP-2RBON3P", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 1000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 2, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 2, "reward_type": "RewardType.INDIVIDUAL", "map_name": "testing_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 10, "framework": "torch", "num_workers": 1, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 50, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algo_args": {"use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "batch_episode": 2, "num_sgd_iter": 2, "vf_loss_coeff": 1.0, "lr": 0.0005, "entropy_coeff": 0.01, "clip_param": 0.3, "vf_clip_param": 10.0, "batch_mode": "complete_episodes"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 2, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_testing_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 10, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000212CF11B8B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 1000, "shuffle_sequences": true, "num_sgd_iter": 2, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 30.104847192764282, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 28.582352941176474, "ram_util_percent": 60.54705882352941}}
